#!/bin/bash
# ---------------------------------------------------------------------------
# start_all.sh  â€”  AG Tech Sec AI Hosting Server Launcher
# Author: Adam Gwozdz (AG Tech Sec)
# 
# Purpose:
#   Starts the complete AI hosting stack including:
#     â€¢ Ollama (text LLMs)
#     â€¢ OpenWebUI (chat frontend)
#     â€¢ InvokeAI (image generation)
#   All services run in Docker with auto-restart and persistent storage.
#   Designed for continuous improvement â€” future features and integrations
#   will follow new AI trends, Cisco automation and cybersecurity research.
# ---------------------------------------------------------------------------
#!/bin/bash
# start_all.sh â€” Start full AI Hosting stack (AG Tech Sec)

set -e

echo "ğŸš€ Starting AG Tech Sec AI Hosting Stack..."

# Create required folders
sudo mkdir -p /mnt/docker_data/openwebui_data
sudo mkdir -p /mnt/backup/models/invokeai
sudo mkdir -p /mnt/backup/models/ollama

# Pull and run Ollama
echo "ğŸ§  Starting Ollama..."
sudo docker rm -f ollama 2>/dev/null || true
sudo docker run -d --name ollama --restart unless-stopped \
  -v /mnt/backup/models/ollama:/root/.ollama/models \
  -p 11434:11434 ollama/ollama

# Pull and run OpenWebUI
echo "ğŸ’¬ Starting OpenWebUI..."
sudo docker rm -f openwebui 2>/dev/null || true
sudo docker run -d --name openwebui --restart unless-stopped \
  -p 3000:8080 \
  -v /mnt/docker_data/openwebui_data:/app/backend/data \
  --add-host=host.docker.internal:host-gateway \
  ghcr.io/open-webui/open-webui:main

# Pull and run InvokeAI
echo "ğŸ¨ Starting InvokeAI..."
sudo docker rm -f invokeai 2>/dev/null || true
sudo docker run -d --name invokeai --restart unless-stopped \
  -p 9090:9090 \
  -v /mnt/backup/models/invokeai:/opt/invokeai/invokeai/backend/image_util/mlsd/models \
  ghcr.io/invoke-ai/invokeai:latest

echo "âœ… All containers launched successfully!"
echo "ğŸŒ Access via:"
echo "   â€¢ OpenWebUI â†’ https://ai.mychatgpt.pl"
echo "   â€¢ InvokeAI  â†’ https://ai.mychatgpt.pl:9090"
echo "   â€¢ Ollama API â†’ http://localhost:11434"


